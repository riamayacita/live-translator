<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Maya Live Language Translator App</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      background-color: #f4f4f4;
      padding: 20px;
    }

    h1 {
      text-align: center;
      color: #333;
    }

    #livePreview {
      padding: 10px;
      margin-bottom: 15px;
      background-color: #ffffff;
      border: 1px solid #ccc;
      min-height: 30px;
      font-style: italic;
      color: #444;
    }

    #originalText, #translatedText {
      margin-bottom: 20px;
      padding: 15px;
      background-color: #fff;
      border: 1px solid #ccc;
      min-height: 50px;
    }

    button {
      margin: 5px;
      padding: 10px 20px;
      font-size: 16px;
    }

    #status {
      margin-top: 10px;
      font-style: italic;
    }
  </style>
</head>
<body>
  <h1>Maya Live Language Translator App</h1>
  <div id="livePreview" placeholder="Live preview..."></div>
  <div id="originalText" placeholder="Original text will appear here..."></div>
  <div id="translatedText" placeholder="Translation will appear here..."></div>

  <button onclick="startRecording()">Start</button>
  <button onclick="stopRecording()">Stop</button>

  <div id="status"></div>

  <script>
    let recognition;
    let isRecording = false;

    async function startRecording() {
      if (!('webkitSpeechRecognition' in window)) {
        alert("Speech Recognition not supported in this browser.");
        return;
      }

      recognition = new webkitSpeechRecognition();
      recognition.continuous = true;
      recognition.interimResults = true;
      recognition.lang = 'en-US';

      const livePreview = document.getElementById("livePreview");
      const originalText = document.getElementById("originalText");
      const translatedText = document.getElementById("translatedText");
      const status = document.getElementById("status");

      let finalTranscript = '';

      recognition.onstart = () => {
        isRecording = true;
        status.innerText = "Recording...";
        requestWakeLock();
      };

      recognition.onerror = (event) => {
        status.innerText = 'Error occurred in recognition: ' + event.error;
      };

      recognition.onend = () => {
        isRecording = false;
        status.innerText = "Stopped.";
        releaseWakeLock();
      };

      recognition.onresult = async (event) => {
        let interimTranscript = '';
        for (let i = event.resultIndex; i < event.results.length; ++i) {
          if (event.results[i].isFinal) {
            const spoken = event.results[i][0].transcript;
            finalTranscript += spoken + '\n';
            originalText.innerText += spoken + '\n';
            livePreview.innerText = ''; // clear live preview
            const translation = await translateText(spoken);
            translatedText.innerText += translation + '\n';
          } else {
            interimTranscript += event.results[i][0].transcript;
          }
        }
        livePreview.innerText = interimTranscript;
      };

      recognition.start();
    }

    function stopRecording() {
      if (recognition && isRecording) {
        recognition.stop();
      }
    }

    async function translateText(text) {
      // Dummy translation for demonstration
      return "(translated) " + text;
    }

    // Wake Lock API
    let wakeLock = null;

    async function requestWakeLock() {
      try {
        if ('wakeLock' in navigator) {
          wakeLock = await navigator.wakeLock.request('screen');
        }
      } catch (err) {
        console.error(`${err.name}, ${err.message}`);
      }
    }

    async function releaseWakeLock() {
      if (wakeLock !== null) {
        await wakeLock.release();
        wakeLock = null;
      }
    }

    document.addEventListener("visibilitychange", () => {
      if (wakeLock !== null && document.visibilityState === "visible") {
        requestWakeLock();
      }
    });
  </script>
</body>
</html>
